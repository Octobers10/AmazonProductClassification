{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning, FitFailedWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FitFailedWarning)\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1185 entries, 0 to 1184\n",
      "Data columns (total 5 columns):\n",
      "ASIN                    1185 non-null object\n",
      "Description             1185 non-null object\n",
      "Price                   1185 non-null float64\n",
      "Verified Subcategory    1185 non-null object\n",
      "Description_New         1185 non-null object\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 46.4+ KB\n"
     ]
    }
   ],
   "source": [
    "info = pd.read_excel('Final Cleaned Data.xlsx')\n",
    "info.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Now we have our models trained on different features. \n",
    "    We want to combine their predictive force to make a even-better-performed model using stacking method\n",
    "    But first we need to preprocess our models to make sure they work on the features that they are good at.\n",
    "    We also use pipeline here just to make the process easier\n",
    "'''\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from joblib import load\n",
    "\n",
    "#Lambda functions are replaced by regular functions since they can't be saved as pickle files\n",
    "#get_text = FunctionTransformer(lambda x: x['Description_New'], validate=False)\n",
    "#get_num = FunctionTransformer(lambda x: x['Price'].values.reshape(-1,1), validate=False)\n",
    "\n",
    "def get_text_func(df):\n",
    "    return df['Description_New']\n",
    "\n",
    "def get_num_func(df):\n",
    "    return df['Price'].values.reshape(-1,1)\n",
    "\n",
    "get_text = FunctionTransformer(get_text_func, validate=False)\n",
    "get_num = FunctionTransformer(get_num_func, validate=False)\n",
    "\n",
    "price_model = load('Price_knn.pkl')\n",
    "text_model_vote = load('Text_voting.pkl')\n",
    "text_model_count = load('Text_RF_count.pkl')\n",
    "text_model_ngram = load('Text_LR_ngram.pkl')\n",
    "text_model_tfidf = load('Text_LR_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8767932489451477\n",
      "0.9324894514767933\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "   DP and MDP Display Adapters       0.98      0.91      0.94        91\n",
      "         HDMI and DVI Adapters       0.83      1.00      0.90        19\n",
      "                          None       0.92      0.92      0.92        60\n",
      "Thunderbolt 3 Display Adapters       0.33      1.00      0.50         1\n",
      "        USB-A Display Adapters       0.95      1.00      0.97        18\n",
      "        USB-C Display Adapters       0.96      0.94      0.95        48\n",
      "\n",
      "                      accuracy                           0.93       237\n",
      "                     macro avg       0.83      0.96      0.86       237\n",
      "                  weighted avg       0.94      0.93      0.93       237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    The first stacking method I tried is VotingClassifier.\n",
    "    It combines each estimator's predicted probability with a given weight (if using soft voting), or a majority vote if using hard voting\n",
    "'''\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "pl_price = Pipeline([('selector', get_num),\n",
    "                     ('clf', price_model)])\n",
    "pl_text_tfidf = Pipeline([('selector', get_text), \n",
    "                    ('vectorizer', TfidfVectorizer()),\n",
    "                    ('clf', text_model_tfidf)])\n",
    "\n",
    "pl_text_ngram = Pipeline([('selector', get_text), \n",
    "                    ('vectorizer', CountVectorizer(ngram_range=(2,3))),\n",
    "                    ('clf', text_model_ngram)])\n",
    "\n",
    "pl_text_count = Pipeline([('selector', get_text), \n",
    "                    ('vectorizer', CountVectorizer()),\n",
    "                    ('clf', text_model_count)])\n",
    "\n",
    "vote = VotingClassifier(\n",
    "    estimators = [\n",
    "        ('1', pl_text_tfidf),\n",
    "        ('2', pl_text_count),\n",
    "        ('3', pl_text_ngram),\n",
    "        ('4', pl_price)\n",
    "                 ],\n",
    "    voting='soft', \n",
    "    weights=[0.25, 0.25, 0.25, 0.25]\n",
    ")\n",
    "\n",
    "print(cross_val_score(vote, info, info['Verified Subcategory'], cv=5, n_jobs=-1).mean())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(info, info['Verified Subcategory'], test_size=0.2, stratify=info['Verified Subcategory'], random_state=1)\n",
    "vote.fit(X_train, y_train)\n",
    "print(vote.score(X_test, y_test))\n",
    "print(classification_report(vote.predict(X_test), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8784810126582279\n",
      "0.919831223628692\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "   DP and MDP Display Adapters       0.94      0.91      0.92        88\n",
      "         HDMI and DVI Adapters       0.87      0.91      0.89        22\n",
      "                          None       0.93      0.89      0.91        63\n",
      "Thunderbolt 3 Display Adapters       0.33      1.00      0.50         1\n",
      "        USB-A Display Adapters       0.95      1.00      0.97        18\n",
      "        USB-C Display Adapters       0.91      0.96      0.93        45\n",
      "\n",
      "                      accuracy                           0.92       237\n",
      "                     macro avg       0.82      0.94      0.86       237\n",
      "                  weighted avg       0.93      0.92      0.92       237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    The second stacking method I tried is StackingClassifier.\n",
    "    The base estimators take inputs first, provide outputs, and the meta estimators take these as inputs. \n",
    "    To be honest I don't know what's the best choice for final estimator but from what I found on different resources, \n",
    "    LogisticRegression is a commonly used one. \n",
    "'''\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('1', pl_text_tfidf),\n",
    "        ('2', pl_text_count),\n",
    "        ('3', pl_text_ngram),\n",
    "        ('4', pl_price)], \n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "print(cross_val_score(stack, info, info['Verified Subcategory'], cv=5, n_jobs=-1).mean())\n",
    "stack.fit(X_train, y_train)\n",
    "print(stack.score(X_test, y_test))\n",
    "print(classification_report(stack.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Final_stack.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Finally, let's save these models! \n",
    "'''\n",
    "from joblib import dump\n",
    "\n",
    "dump(vote, \"Final_vote.pkl\")\n",
    "dump(stack, \"Final_stack.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "   DP and MDP Display Adapters       1.00      0.98      0.99       429\n",
      "         HDMI and DVI Adapters       0.96      1.00      0.98       110\n",
      "                          None       0.98      0.98      0.98       300\n",
      "Thunderbolt 3 Display Adapters       0.86      1.00      0.92        12\n",
      "        USB-A Display Adapters       0.99      1.00      0.99        97\n",
      "        USB-C Display Adapters       0.99      0.99      0.99       237\n",
      "\n",
      "                      accuracy                           0.99      1185\n",
      "                     macro avg       0.96      0.99      0.98      1185\n",
      "                  weighted avg       0.99      0.99      0.99      1185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(vote.predict(info), info['Verified Subcategory']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37464bitanaconda3virtualenv6a18c55a51c948acbf356541ef072a99"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
