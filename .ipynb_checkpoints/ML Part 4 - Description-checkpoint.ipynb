{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning, FitFailedWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FitFailedWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1185 entries, 0 to 1184\n",
      "Data columns (total 8 columns):\n",
      "ASIN                    1185 non-null object\n",
      "Description             1185 non-null object\n",
      "Price                   1185 non-null float64\n",
      "Verified Subcategory    1185 non-null object\n",
      "Description_New         1185 non-null object\n",
      "Description_Count       1185 non-null object\n",
      "Description_Ngram       1185 non-null object\n",
      "Description_Tfidf       1185 non-null object\n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 74.2+ KB\n"
     ]
    }
   ],
   "source": [
    "info = pd.read_excel('Final Cleaned Data.xlsx')\n",
    "info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Model Selection:\n",
    "        Here I choose MultinomialNB, RandomForestClassifier, and LogisticRegression\n",
    "        1. MultinomialNB: \n",
    "            - can calculate the probability of the label (for this project: Category) given these word vectors\n",
    "        2. RandomForestClassifier:\n",
    "            - It overall performs well on classification problems \n",
    "            - I think the way Decision Tree works is similar to how human would classify the ASIN given the description\n",
    "        3. LogisticRegression:\n",
    "            - A simple and easy-to-understand model that always worth a try\n",
    "        There are other models such as neural network that I believe will also perform well on this task. But for this project I will just use traditional machine learning models\n",
    "'''\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "nb = MultinomialNB()\n",
    "rf = RandomForestClassifier()\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Feature Engineering:\n",
    "        Here I choose some of the most common feature engineering tools for NLP are bag-of-word, n-gram, and tfidf\n",
    "        1. Bag-of-word: \n",
    "            - word frequency count; \n",
    "            - one of the easiest but useful NLP feature engineering tool\n",
    "        2. N-gram: \n",
    "            - N-consecutive word frequency count; \n",
    "            - taking the context of each word into account\n",
    "        3. Tfidf: \n",
    "            - the word's weight is counted based on its frequency on the document and the corpus; \n",
    "            - useful for determine the document's topic among a collection of documents(corpus)\n",
    "        \n",
    "        Since all these products are related to av display technologies, I would expect they share similar description;\n",
    "        Thus, TfidfVectorizer might be the best-perform vectorizer; \n",
    "        but I also include bag-of-words and ngram to have more variety on features\n",
    "'''\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "X_count = CountVectorizer().fit_transform(info['Description_New'])\n",
    "X_ngram = CountVectorizer(ngram_range=(2,3)).fit_transform(info['Description_New'])\n",
    "X_tfidf = TfidfVectorizer().fit_transform(info['Description_New'])\n",
    "y = info['Verified Subcategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Hyperparameter Tuning: \n",
    "        There are a few hyperparameter tuning methods that are commonly used: GridSearchCV, RandomizedSearchCV, Bayesian Optimization, etc. \n",
    "        I choose GridSearchCV for MultinomialNB and RandomizedSearchCV for RandomForestClassifier and LogisticRegression\n",
    "        because of the dimension of each model's parameter list and these methods are provided by sklearn library  \n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "param_nb = {'alpha': [0.5, 1, 2, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]}\n",
    "param_rf = {\n",
    "    'n_estimators': [20, 50, 100, 150, 200],\n",
    "    'max_depth': [10, 30, 50, 70, None],\n",
    "    'bootstrap': [True, False]\n",
    "    }\n",
    "param_lr = {\n",
    "    'C': [1, 10, 100, 1000, 1500, 2000, 2500],\n",
    "    'max_iter': [100, 200, 300, 400, 500, None],\n",
    "    'fit_intercept' : [True, False],\n",
    "    'multi_class' : ['auto', 'ovr', 'multinomial'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb score: 0.8135021097046413\n",
      "nb best params: {'alpha': 1}\n",
      "rf score: 0.8438818565400844\n",
      "rf best params: {'n_estimators': 50, 'max_depth': None, 'bootstrap': False}\n",
      "lr score: 0.839662447257384\n",
      "lr best params: {'solver': 'saga', 'multi_class': 'ovr', 'max_iter': 100, 'fit_intercept': True, 'C': 1500}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Fitting bag-of-word to all three models with hyperparameter tuning\n",
    "'''\n",
    "\n",
    "gs_nb1 = GridSearchCV(estimator=nb, param_distributions=param_nb, cv=5, verbose=0)\n",
    "gs_nb1.fit(X_count, y)\n",
    "print(\"nb score:\", gs_nb1.best_score_)\n",
    "print(\"nb best params:\", gs_nb1.best_params_)\n",
    "gs_rf1 = RandomizedSearchCV(estimator=rf, param_distributions=param_rf, cv=5, verbose=0)\n",
    "gs_rf1.fit(X_count, y)\n",
    "print(\"rf score:\", gs_rf1.best_score_)\n",
    "print(\"rf best params:\", gs_rf1.best_params_)\n",
    "gs_lr1 = RandomizedSearchCV(estimator=lr, param_distributions=param_lr, cv=5, verbose=0)\n",
    "gs_lr1.fit(X_count, y)\n",
    "print(\"lr score:\", gs_lr1.best_score_)\n",
    "print(\"lr best params:\", gs_lr1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb score: 0.7856540084388186\n",
      "nb best params: {'alpha': 1}\n",
      "rf score: 0.8042194092827003\n",
      "rf best params: {'n_estimators': 100, 'max_depth': 70, 'bootstrap': False}\n",
      "lr score: 0.8540084388185653\n",
      "lr best params: {'solver': 'liblinear', 'multi_class': 'ovr', 'max_iter': 300, 'fit_intercept': False, 'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Fitting n-gram to all three models with hyperparameter tuning\n",
    "'''\n",
    "gs_nb2 = GridSearchCV(estimator=nb, param_distributions=param_nb, cv=5, verbose=0)\n",
    "gs_nb2.fit(X_ngram, y)\n",
    "print(\"nb score:\", gs_nb2.best_score_)\n",
    "print(\"nb best params:\", gs_nb2.best_params_)\n",
    "gs_rf2 = RandomizedSearchCV(estimator=rf, param_distributions=param_rf, cv=5, verbose=0)\n",
    "gs_rf2.fit(X_ngram, y)\n",
    "print(\"rf score:\", gs_rf2.best_score_)\n",
    "print(\"rf best params:\", gs_rf2.best_params_)\n",
    "gs_lr2 = RandomizedSearchCV(estimator=lr, param_distributions=param_lr, cv=5, verbose=0)\n",
    "gs_lr2.fit(X_ngram, y)\n",
    "print(\"lr score:\", gs_lr2.best_score_)\n",
    "print(\"lr best params:\", gs_lr2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb score: 0.6962025316455696\n",
      "nb best params: {'alpha': 0.5}\n",
      "rf score: 0.8430379746835441\n",
      "rf best params: {'n_estimators': 200, 'max_depth': 70, 'bootstrap': False}\n",
      "lr score: 0.8649789029535866\n",
      "lr best params: {'solver': 'saga', 'multi_class': 'auto', 'max_iter': 400, 'fit_intercept': True, 'C': 100}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Fitting tfidf to all three models with hyperparameter tuning\n",
    "'''\n",
    "gs_nb3 = GridSearchCV(estimator=nb, param_distributions=param_nb, cv=5, verbose=0)\n",
    "gs_nb3.fit(X_tfidf, y)\n",
    "print(\"nb score:\", gs_nb3.best_score_)\n",
    "print(\"nb best params:\", gs_nb3.best_params_)\n",
    "gs_rf3 = RandomizedSearchCV(estimator=rf, param_distributions=param_rf, cv=5, verbose=0)\n",
    "gs_rf3.fit(X_tfidf, y)\n",
    "print(\"rf score:\", gs_rf3.best_score_)\n",
    "print(\"rf best params:\", gs_rf3.best_params_)\n",
    "gs_lr3 = RandomizedSearchCV(estimator=lr, param_distributions=param_lr, cv=5, verbose=0)\n",
    "gs_lr3.fit(X_tfidf, y)\n",
    "print(\"lr score:\", gs_lr3.best_score_)\n",
    "print(\"lr best params:\", gs_lr3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "   DP and MDP Display Adapters       0.90      0.99      0.94       127\n",
      "         HDMI and DVI Adapters       0.78      0.82      0.80        34\n",
      "                          None       0.90      0.81      0.85        90\n",
      "Thunderbolt 3 Display Adapters       1.00      0.75      0.86         4\n",
      "        USB-A Display Adapters       1.00      0.97      0.98        30\n",
      "        USB-C Display Adapters       0.96      0.90      0.93        71\n",
      "\n",
      "                      accuracy                           0.91       356\n",
      "                     macro avg       0.92      0.87      0.89       356\n",
      "                  weighted avg       0.91      0.91      0.91       356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    LogisticRegression model with tfidf feature is the best-performing model;\n",
    "    I want to take a deeper look into how the model performs on each category and its different scoring\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, stratify=y, test_size=0.3)\n",
    "best_model = gs_lr3.best_estimator_\n",
    "score_best = cross_val_score(best_model, X_tfidf, y, n_jobs=-1, verbose=0, cv=5)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging score: 0.8556962025316455\n",
      "Best individual estimator score: 0.861603375527426\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Overall score of 0.86 is not bad, and we have used hyperparameter tuning to combat overfitting problem.\n",
    "    But still I wonder if we can further reduce model variance and biases.\n",
    "    One way to reduce model variance is using ensemble method: Bagging \n",
    "'''\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bg = BaggingClassifier(\n",
    "    base_estimator=best_model,\n",
    "    n_estimators=10\n",
    ")\n",
    "\n",
    "#bg.fit(X_train, y_train)\n",
    "score_bg = cross_val_score(bg, X_tfidf, y, n_jobs=-1, verbose=0)\n",
    "print(\"Bagging score:\", score_bg.mean())\n",
    "print(\"Best individual estimator score:\", score_best.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: 0.8329113924050633\n",
      "Best individual estimator score: 0.861603375527426\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Boosting is another ensemble method that might reduce modelâ€™s bias\n",
    "'''\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100)\n",
    "score_gb = cross_val_score(gb, X_tfidf, y, n_jobs=-1, verbose=0, cv=5)\n",
    "print(\"Gradient Boosting score:\", score_gb.mean())\n",
    "print(\"Best individual estimator score:\", score_best.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Text_LR_tfidf.pkl']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Since Bagging and Boosting don't seem to make improvements\n",
    "    We will just save the best estimators for each engineered feature\n",
    "'''\n",
    "import joblib\n",
    "\n",
    "joblib.dump(gs_rf1.best_estimator_, \"Text_RF_count.pkl\")\n",
    "joblib.dump(gs_lr2.best_estimator_, \"Text_LR_ngram.pkl\")\n",
    "joblib.dump(gs_lr3.best_estimator_, \"Text_LR_tfidf.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
